{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Matrix Generation\n",
    "### load raw .csv files\n",
    "### create URM sparse matrix\n",
    "### create ICM sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed libraries and set datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "\n",
    "comp_year='2020'\n",
    "data_folder_path='../Data/2020'\n",
    "matrix_dir='../Processed Matrices'\n",
    "URM_file_name='data_train.csv'\n",
    "URM_file_path= os.path.join(data_folder_path,URM_file_name);\n",
    "ICM_file_prefix='data_ICM_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowSplit(line):\n",
    "    \"\"\"split line into cols and return as a tuple\"\"\"\n",
    "    split= line.split(',')\n",
    "    split[-1]=float(split[-1].replace(\"\\n\",\"\"))\n",
    "    split[0:-1]=[int(i) for i in split[0:-1]]\n",
    "    \n",
    "    return tuple(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Create sparse ICM matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of seperate ICM files\n",
    "icm_files= [i.replace(\" \",\"_\") for i in os.listdir(data_folder_path) if os.path.isfile(os.path.join(data_folder_path,i)) and ICM_file_prefix in i]\n",
    "\n",
    "# create sparse coo matrix from each file\n",
    "ICM_list=[]\n",
    "sum_col=0\n",
    "for file in icm_files:\n",
    "    file_tuples=[]\n",
    "    icm_file=open(os.path.join(data_folder_path, file))\n",
    "    _=icm_file.readline()\n",
    "    for line in icm_file:\n",
    "        file_tuples.append(rowSplit(line))\n",
    "    itemList, attrList, valueList= zip(*file_tuples)\n",
    "    ICM_list.append(sps.coo_matrix((valueList,(itemList, attrList))))\n",
    "    \n",
    "#stack matrices to create full ICM and save\n",
    "ICM_all=sps.hstack(ICM_list)\n",
    "sps.save_npz(matrix_dir+\"/ICM_simple_coo_\"+comp_year+\".npz\", ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero=ICM_all.nonzero()\n",
    "ICM_all_nonweighted=sps.coo_matrix((np.ones(ICM_all.nnz),(nonzero[0],nonzero[1])))\n",
    "sps.save_npz(matrix_dir+\"/ICM_nonweighted_simple_coo_\"+comp_year+\".npz\", ICM_all_nonweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Create sparse URM matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_file= open(URM_file_path, 'r')\n",
    "\n",
    "URM_tuples=[]\n",
    "\n",
    "# skip first line containing column names\n",
    "_=URM_file.readline()\n",
    "\n",
    "for line in URM_file:\n",
    "    URM_tuples.append(rowSplit(line))\n",
    "\n",
    "#create user,item &rating lists\n",
    "userList, itemList, ratingList= list(zip(*URM_tuples))\n",
    "\n",
    "#consruct sparse URM matrix and save\n",
    "import scipy.sparse as sps\n",
    "\n",
    "URM_all=sps.coo_matrix((ratingList,(userList,itemList)))\n",
    "sps.save_npz(matrix_dir+\"/URM_simple_coo_\"+comp_year+\".npz\", URM_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas and train_test_split to create train and test sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#create dataframe to be split\n",
    "URM_dict={'user':userList, 'item':itemList, 'rating':ratingList}\n",
    "URM_all_df= pd.DataFrame(URM_dict)\n",
    "\n",
    "#split URM data to the 3 sets\n",
    "URM_train_df, URM_valid_df = train_test_split(URM_all_df, test_size=0.3,shuffle=True, random_state=41148)\n",
    "\n",
    "#create sparse matrices and save\n",
    "train_userList = list(URM_train_df['user'])\n",
    "train_itemList = list(URM_train_df['item'])\n",
    "train_ratingList = list(URM_train_df['rating'])\n",
    "URM_train = sps.coo_matrix((train_ratingList , (train_userList , train_itemList)))\n",
    "sps.save_npz(matrix_dir+\"/URM_train_simple_coo_\"+comp_year+\".npz\" , URM_train)\n",
    "\n",
    "valid_userList = list(URM_valid_df['user'])\n",
    "valid_itemList = list(URM_valid_df['item'])\n",
    "valid_ratingList = list(URM_valid_df['rating'])\n",
    "URM_valid = sps.coo_matrix((valid_ratingList , (valid_userList , valid_itemList)))\n",
    "sps.save_npz(matrix_dir+\"/URM_valid_simple_coo_\"+comp_year+\".npz\" , URM_valid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
